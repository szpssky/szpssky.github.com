---
title: 《Deep Learning》笔记 —— 深度学习中的正则化
date: 2017-08-27 08:00:00
categories:
- Deep Learning Book
tags:
- Deep Learning
comments: true
mathjax: true
---

### 参数范数惩罚

许多正则化的方法通过对目标函数$J$添加一个参数范数惩罚$\Omega(\theta)$，限制模型(如神经网络、线性回归或逻辑回归)的学习能力。我们将正则化后的目标记为$\tilde{J}$：
$$
\tilde{J}(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)
$$
其中$\alpha\in [0,\infty]$是权衡惩罚项$\Omega$和目标函数$\tilde{J}(X,\theta)$相对贡献的超参数。$\alpha$为0则没有正则化，$\alpha$越大，对应正则化惩罚越大。

在神经网络中，参数包括每一层仿射变换的权重和偏置，通常只对权重做惩罚，而不对偏置做正则惩罚，每个偏置只控制一个单变量，即使不对其进行正则化也不会导致太大方差，此外正则化偏置参数可能导致欠拟合。

#### $L^2$参数正则化

这个正则化的策略是向目标函数添加一个正则项$\Omega(\theta)=\frac{1}{2}||w||_2^2$，使权重更接近原点。
<!-- more -->

添加正则化项后一个模型具有以下目标函数：
$$
\tilde{J}(w;X,y)=\frac{\alpha}{2}w^Tw+J(w;X,y)
$$

与之对应的梯度为：
$$
\nabla_w\tilde{J}(w;X,y)=\alpha w+\nabla_wJ(w;X,y)
$$
使用单步梯度下降更新权重：

$$
w \leftarrow w-\epsilon(\alpha w+\nabla_wJ(w;X,y)) 
$$
即：
$$
w \leftarrow (1-\epsilon \alpha)w-\epsilon \nabla_wJ(w;X,y)
$$

每步执行通常的梯度更新前先收缩权重向量。

令$w^*$为未正则化的目标函数取得最小误差时权重，即$w^*=\arg\min_wJ(w)$，在$w^*$邻域做二次近似则近似的$\hat J(\theta)$：
$$
\hat J(\theta)=J(w^*)+\frac{1}{2}(w-w^*)^TH(w-W^*)
$$
其中$H$是$J$在$w^*$处计算的Hessian矩阵，因为在$w^*$处取得最优，所以一阶导为0，所以二次近似项中没有一次项，又因$w^*$是J的一个最优点，所以$H$是半正定的。

当$\tilde{J}$取得最小时，其梯度为0：
$$
\nabla_w\tilde{J}(w)=H(w-w^*)
$$

对上式添加权重衰减梯度，最小化正则化后$\hat J$，$\tilde{w}$表示此时的最优点：
$$
\alpha\tilde{w}+H(\tilde{w}-w^*) =0 \\
(H+\alpha I)\tilde{w}=Hw^* \\
\tilde{w}=(H+\alpha I)^{-1}Hw^*
$$

因为$H$是实对称的，将其分解为一个对角矩阵$\Lambda$和一组特征向量的标准正交基$Q$，并且$H=Q\Lambda Q^T$：
$$
\begin{aligned}
\tilde{w} & =(Q\Lambda Q^T+\alpha I)^{-1}Q\Lambda Q^Tw^* \\
& =[Q(\Lambda+\alpha I)Q^T]^{-1}Q\Lambda Q^T w^* \\
& =Q(\Lambda + \alpha I)^{-1}\Lambda Q^Tw^*
\end{aligned}
$$

权重衰减沿着$H$特征向量所定义的轴缩放$w^*$，具体会根据$\frac{\lambda_i}{\lambda_i+\alpha}$因子缩放与$H$第$i$个特征向量对齐的$w^*$分量。

沿着$H$特征值较大的方向正则化的影响较小，而$\lambda_i \ll \alpha$的分量会搜索到几乎为0。

只有在显著减小目标函数的方向上的参数会保留相对完好，在对目标函数减小的方向没有帮助的方向上的权重会因正则化而被衰减掉。

#### $L^1$正则化

$L^1$正则化被定义为：
$$
\Omega(\theta)=||w||_1=\sum_i|w_i|
$$
即各个参数的绝对值之和，正则化的目标函数$\tilde{J}(w;X,y)$：
$$
\tilde{J}(w;X,y)=\alpha ||w||_1+J(w;X,y)
$$

对应的梯度为：
$$
\nabla_w \tilde{J}(w;X,y)=\alpha sign(w)+\nabla_wJ(w;X,y)
$$

正则化对梯度的影响不在是线性缩放每个$w_i$，而是添加一项与$sign(w)$同号的常数。

同样的假定模型为简单的线性模型具有二次代价函数，可以通过泰勒级数表示则：
$$
\nabla_w\hat J(w)=H(w-w^*)
$$

$L^1$在完全一般化的Hessian的情况下，无法得到清晰的代数表达式，进一步假设Hessian是对角的即$H=diag([H_{1,1},\dots,H_{n,n}])$,其中$H_{i,i} > 0$。

将$L^1$正则化目标函数的二次近似分解成关于参数的求和：
$$
\hat J(w;X,y)=J(w^*;X,y)+\sum_i\big[\frac{1}{2}H_{i,i}(w_i,w_i^*)^2+\alpha|w_i|\big]
$$

下列这个解析解可以最小化上诉近似代价函数：
$$
w_i=sign(w_i^*)\max\big\{|w_i^*|-\frac{\alpha}{H_{i,i}},0\big\}
$$

对每一个$i$，$w_i^* > 0$会有两种结果：

1）$w_i^* \leq \frac{\alpha}{H_{i,i}}$，正则化后目标$w_i$最优值是$w_i=0$，在方向i上$J(w;X,y)$对$\hat j(w;X,y)$的贡献被抵消，$L^1$正则将$w_i$推向0。

2）$w_i^* > \frac{\alpha}{H_{i,i}}$，正则化不会将$w_i$的最优值推向0，而仅仅在这个方向上移动$\frac{\alpha}{H_{i,i}}$。

$w_i^* < 0$的情况与之类似。

相比$L^2$正则化，$L^1$正则化将会产生更稀疏的解。

由$L^1$正则导出的稀疏性质广泛的应用于特征选择机制，可从可用的特征子集中选择出有意义的特征，简化机器学习问题。

### 数据集增强

让机器学习模型泛化更好的最好的办法是使用更多的数据进行训练，针对数据集有限的情况，解决这个问题的一种方法是创建假数据并添加到训练集中。在对象识别中，如沿图像每个方向平移几个像素，旋转图像或缩放图像等。在神经网络中注入噪声也可以看做数据增强的一种方式。

### 噪声鲁棒性

对于某些模型而言相输入添加方差极小的噪声等价于对权重施加范数惩罚，在一般情况下，注入噪声远比简单地收缩参数强，特别是噪声被添加进隐藏单元，最小化带权重噪声的$J$等同于最小化附带正则项，这种形式的正则化鼓励参数进入权重小扰动对输出相对影响较小的参数空间区域。

还有一种方法是向输出目标注入噪声，大多数数据集的y标签都有一定错误，错误的y不利于最大化$\log p(y|x)$，避免这种情况的一种方法是显示地对标签上噪声进行建模，例如可以假设小常数$\epsilon$，训练集标记$y$是正确的概率是$1-\epsilon$，任何其他可能的标签也可能是正确的，这个假设很容易与代价函数结合，而不需要显式抽取噪声样本，例如标签平滑通过把确切的分类目标从0和1替换为$\frac{\epsilon}{k-1}$和$1-\epsilon$，正则化$k$个输出的softmax函数模型。

通常使用softmax函数和明确目标的最大似然学习可能永远不会收敛，因为softmax函数永远无法正真预测0概率和1概率，因此可能会继续学习到越来越大的权重，是预测更极端，使用权重衰减正则化可以防止这种情况，但标签平滑的优势是能够防止追求确切的概率，而不阻碍学习正确分类。

### 多任务学习

多任务学习通过合并几个任务中的样例来提高泛化，可以视为对参数施加软约束。

### 提取终止

通常会观察到训练误差会随着施加的推移逐渐降低但验证误差会再次上升，所以提前终止策略也是有效降低泛化误差的一种手段，这也是深度学习中最常用的正则化形式。

### Bagging和其他集成方法

Bagging是通过结合几个模型降低泛化误差的技术，主要想法是分别训练几个不同的模型，然后让所有模型表决测试样例的输出，被称为模型平均。

神经网络即使所有模型都在同一数据集上训练，也能够找到足够多的不同解，神经网络中随机初始化的差异、小批量的随机选择、超参数或不同输出的非确定性实现往往足以使的集成中的不同成员具有独立的误差。

### Dropout

Dropout提供了正则化一大类模型的方法，可被认为是集成大量深层神经网络的实用Bagging方法。

Dropout训练集成包括从基础网络中除去非输出单元后形成的子网络，其目标是在指数级数量的神经网络上近似Bagging过程，在训练中使用Dropout，在每次小批量中加载一个样本，然后随机抽样应用于网络中所有输入和隐藏单元的不同二值掩码。

Dropout和Bagging训练的一个显著区别是，在Bagging下所有模型都是独立的，并且每个模型都将在其相应的数据集上训练到收敛，而Dropout上大部分模型都没有显式的被训练，因为通常神经网络会很大，在单个步骤里训练一小部分子网络，参数共享使得剩余的子网络也能有很好的参数设定。

在Dropout中，通过掩码$\mu$定义每个子模型的概率分布$p(y|x,\mu)$，所有掩码的算术平均值为：
$$
\sum_\mu p(\mu)p(y|x,\mu)
$$

其中$p(\mu)$是训练时采样$\mu$的概率分布。这个求和包含多达指数级的项，除非模型能够被简化否则不可能计算出来，通常通过采样近似推断。但是更好的方法是使用集成成员的几何平均而不是算术平均，这个近似整个集成。

多个概率分布的几何平均不能保证是一个概率分布，为了保证结果是一个概率分布，要求没有子模型给某一事件分布的概率为0，并重新标准化所得分布，通过几何平均直接定义的非标准化概率分布如下：
$$
\tilde{p}_{ensenmble}(y|x)=\sqrt[2^d]{\prod_\mu p(y|x,\mu)}
$$

其中d是可被丢弃的单元数，为了进行预测，需重新进行标准化：
$$
p_{ensemble}(y|x)=\frac{\tilde{p}(y|x)}{\sum\nolimits_{y'}\tilde{p}_{ensemble}(y')x}
$$

我们可以通过评估模型中的$p(y|x)$来近似$p_{ensemble}$，将单元$i$的输出权重乘以单元$i$的被包含概率，目的是得到该单元输出的正确期望，这种方法被称为权重比例推断。(详见Deep Learning书中P163)

Dropout比其他标准的计算开销小的正则化更有效，Dropout也可以与其他正则化一起使用，其优点是：

1）计算方便，训练过程中参数n个随机二进制数与状态相乘，每个样本每次更新只需$O(n)$的计算复杂度。

2）不限制适用的模型或训练过程，几乎在所有分布式表示且可以用随机梯度下降训练的模型上都表现良好。

Dropout是一个正则化技术，它减小了模型的有效容量，为了抵消这个影响必须增大模型规模，使用Dropout时最佳验证集的误差会低很多，但这是以更大的模型和更多的训练算法迭代次数换来的，对于非常大的数据集，正则化带来的泛化误差减小得很小，在这些情况下使用Dropout和更大的模型的计算代价可能超过正则化带来的好处。

此外Dropout不仅仅是训练一个Bagging的集成模型，而且是共享隐藏单元的集成模型，这意味着每个隐藏单元不管是否在模型中，都必须能表现良好，因此每个隐藏单元不仅是一个很好的特征，更要在许多情况下表现良好。

Dropout强大的大部分原因是其施加了在隐藏层的掩码噪声，可以看作对输入内容的信息高度智能化、自适应破坏的一种形式，破坏提取的特征而不是破坏原始值，让破坏过程充分利用该模型获得的关于输入分布的所有知识。







